{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando pacotes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz \n",
    "from fuzzywuzzy import process\n",
    "from fuzzyJoao import partial_ratio\n",
    "from argparse import ArgumentParser\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from IPython.display import clear_output, display\n",
    "import multiprocessing\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_texto = pd.read_csv(\"/scratch/derickmath/text_processing/2006-2010/exames_texto.csv\")\n",
    "dicionario = pd.read_csv(\"/scratch/derickmath/text_processing/2006-2010/DicionarioECG.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time parallel for 200 lines = 123.9019660949707\n",
    "\n",
    "time sequential for 200 lines = 3.2906479835510254"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-06741cc4597b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtime100it\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdados_texto\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conteudo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"aux.rtf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/scratch/derickmath/text_processing/2006-2010/runrtf.sh\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"aux.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"UTF-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ls\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-l\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \"\"\"\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    767\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    770\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1445\u001b[0m                             \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m                             \u001b[0merrpipe_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrpipe_write\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1447\u001b[0;31m                             restore_signals, start_new_session, preexec_fn)\n\u001b[0m\u001b[1;32m   1448\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_child_created\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "text = []\n",
    "for i in range(len(dados_texto[\"conteudo\"])):\n",
    "    time100it = time.time()\n",
    "    print(dados_texto['conteudo'][i], file=open(\"aux.rtf\", \"w\"))\n",
    "    sh = subprocess.call([\"sh\", \"/scratch/derickmath/text_processing/2006-2010/runrtf.sh\"])\n",
    "    file = open(\"aux.txt\", encoding=\"UTF-8\")\n",
    "    text.append(file.read())\n",
    "    clear_output(wait=True)\n",
    "    if(i%100 == 0):\n",
    "        print(\"it = \", i, len(dados_texto['conteudo']), i/len(dados_texto['conteudo']))\n",
    "        print(\"time = \", time.time() - start_time)\n",
    "        print(\"100 it time = \", time.time() - time100it)\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_texto[\"conteudo_txt\"] = text\n",
    "dados_texto.to_csv('/scratch/derickmath/text_processing/2006-2010/exames_texto_txt__.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_texto = pd.read_csv(\"/scratch/derickmath/text_processing/2006-2010/exames_texto_txt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função que recebe o dicionário e uma String e retorna uma lista com a similaridade de cada doença à String\n",
    "def checarSimilaridadeDoencas(texto, dicionario, id_evento):\n",
    "    listaScore = []\n",
    "    for row in dicionario.itertuples():\n",
    "        maiorScore = 0\n",
    "        maiorScoreL = []\n",
    "        for diag in row:\n",
    "            if ((type(diag) is not int and type(diag) is not float) and (type(texto) is not float)):\n",
    "                score = partial_ratio(diag.lower(), texto.lower())\n",
    "                if score[3] > maiorScore: \n",
    "                    maiorScore = score[3]\n",
    "                    maiorScoreL = score\n",
    "        if (maiorScore > 60):\n",
    "            listaScore.append([id_evento, row[1], maiorScoreL[0], maiorScoreL[1], maiorScoreL[2], maiorScoreL[3], texto])\n",
    "#         else:\n",
    "#             listaScore.append([id_evento, row[1], maiorScoreL[0], maiorScoreL[1], maiorScoreL[2], maiorScoreL[3], texto])\n",
    "    return listaScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432198"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dados_texto['conteudo_txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = multiprocessing.cpu_count()\n",
    "start_time = time.time()\n",
    "resultados_match_p = Parallel(n_jobs = num_cores)(delayed(checarSimilaridadeDoencas)\n",
    "                              (dados_texto['conteudo_txt'][i], dicionario, dados_texto['id'][i])\n",
    "                    for i in range(len(dados_texto['conteudo_txt'])))\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"oi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "resultado_n_vazio = [resultados_match_p[x] for x in range(len(resultados_match_p)) if resultados_match_p[x] != []]\n",
    "\n",
    "for x in resultado_n_vazio:\n",
    "    for y in x:\n",
    "        result.append(y)\n",
    "result = pd.DataFrame(result, columns = [\"id\", \"class\", \"inicio\", \"fim\", \"trecho\", \"score\", \"texto\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_vazio = [resultados_match_p[x] for x in range(len(resultados_match_p)) if resultados_match_p[x] == []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196253"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resultado_vazio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 68\n"
     ]
    }
   ],
   "source": [
    "corte_classes = [84, 85, 96, 84, 97, 94, 81, 100, 83, 95, 83, 83, 81, 92, 95, 81, 85, 92, 84, 83, 86, 89, 83, 92, 93, 92, 83, 83, 87, \n",
    "                100, 92, 80, 84, 87, 91, 84, 100, 81, 100, 100, 88, 100, 81, 90, 100, 83, 90, 81, 86, 83, 96, 82, 97, 85, 90, 81, 81, 97,\n",
    "                95, 97, 84, 81, 84, 89, 86, 89, 83, 95]\n",
    "ordem_classes = ['Sobrecarga ventricular esquerda (critérios de Romhilt-Estes)',\n",
    " 'Sobrecarga atrial esquerda', 'Sobrecarga biventricular',\n",
    " 'Corrente de lesão subendocárdica', 'Bloqueio atrioventricular 2:1',\n",
    " 'Bloqueio atrioventricular total', 'Bloqueio atrioventricular de 1° grau',\n",
    " 'Sobrecarga ventricular esquerda( critérios de voltagem)',\n",
    " 'ECG dentro dos limites da normalidade para idade e sexo ',\n",
    " 'Sobrecarga biatrial', 'Possível inversão de posicionamento de eletrodos',\n",
    " 'Extrassístoles supraventriculares', 'Desvio do eixo do QRS para esquerda',\n",
    " 'Taquicardia supraventricular ', 'Taquicardia sinusal',\n",
    " 'área eletricamente inativa', 'Bradicardia sinusal', 'Pausa sinusal',\n",
    " 'Sobrecarga atrial direita', 'Bloqueio de ramo direito',\n",
    " 'Extrassístoles ventriculares' ,'Intervalo QT prolongado',\n",
    " 'Arritmia sinusal', 'Dextrocardia ', 'Flutter atrial',\n",
    " 'Bloqueio de ramo esquerdo',\n",
    " 'Alterações primárias da repolarização ventricular ',\n",
    " 'Isquemia subendocárdica', 'Ritmo juncional',\n",
    " 'Sobrecarga ventricular direita', 'Bloqueio atrioventricular avançado',\n",
    " 'Bloqueio divisional posteroinferior do ramo esquerdo',\n",
    " 'Sobrecarga ventricular esquerda (critérios de voltagem)',\n",
    " 'Bloqueio atrioventricular de 2° grau Mobitz I',\n",
    " 'Bloqueio atrioventricular de 2° grau Mobitz II',\n",
    " 'Pré-excitação ventricular tipo Wolff-Parkinson-White',\n",
    " 'Sistema de estimulação cardíaca normofuncionante',\n",
    " 'Alterações da repolarização ventricular atribuídas à ação digitálica',\n",
    " 'Bloqueio de ramo direito e bloqueio divisional  posteroinferior do ramo esquerdo',\n",
    " 'Progressão lenta de R nas derivações precordiais ',\n",
    " 'Corrente de lesão subepicárdica - provável infarto agudo do miocárdio com supradesnivelamento de ST',\n",
    " 'Suspeita de Síndrome de  Brugada, repetir V1-V2 em derivações superiores',\n",
    " 'Desvio do eixo do QRS para direita', 'Ritmo atrial ectópico',\n",
    " 'Intervalo PR curto', 'Ritmo atrial multifocal',\n",
    " 'Sistema de estimulação cardíaca com disfunção',\n",
    " 'Bloqueio divisional anterossuperior do ramo esquerdo',\n",
    " 'Distúrbio de condução do ramo direito', 'Taquicardia atrial',\n",
    " 'Batimento de escape atrial','Fibrilação atrial',\n",
    " 'Taquicardia ventricular não sustentada',\n",
    " 'Taquicardia ventricular sustentada',\n",
    " 'Bloqueio de ramo direito e bloqueio divisional anterossuperior do ramo esquerdo',\n",
    " 'Batimento de escape supraventricular', 'Batimento de escape ventricular ',\n",
    " 'Batimento de escape juncional', 'Taquicardia juncional',\n",
    " 'Taquicardia atrial multifocal ', 'Corrente de lesão subepicárdica',\n",
    " 'Alterações inespecíficas da repolarização ventricular',\n",
    " 'Alterações secundárias da repolarização ventricular',\n",
    " 'Distúrbio de condução do ramo esquerdo', 'Repolarização precoce',\n",
    " 'Ausência de sinal eletrocardiográfico que impede a análise',\n",
    " 'Traçado com qualidade técnica insuficiente', 'Síndrome de Brugada']\n",
    "print(len(ordem_classes), len(corte_classes))\n",
    "##observações\n",
    "##1 - bav1, regra para excluir todos que não forem \"primeiro grau\", cerca de 80 falsos positivos com a nota de corte 81\n",
    "##2 - problema no \"sve critérios de voltagem\" (aparece 2 vezes, verificar) - cuidado com \"(\" no dicionário\n",
    "##3 - problema no ritmo juncional\n",
    "##4 - char estranho para mobitz I e II (33, 34)\n",
    "##5 - padrão vazio para Sistema de estimulação cardíaca normofuncionante (36)\n",
    "##6 - problema crase Alterações da repolarização ventricular atribuídas à ação digitálica (37)\n",
    "##7 - padrão vazio para Bloqueio de ramo direito e bloqueio divisional  posteroinferior do ramo esquerdo (38)\n",
    "##8 - padrão vazio para Progressão lenta de R nas derivações precordiais (39)\n",
    "##9 - padrão vazio para Corrente de lesão subepicárdica - provável infarto agudo do miocárdio com supradesnivelamento de ST (40)\n",
    "##10 - padrão vazio para (41)\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[(result['class'] == ordem_classes[-1]) & (result['score'] <= 100) & (result['score'] >= 80)].groupby([\"trecho\", \"score\"]).id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "certos = [result[(result['class'] == ordem_classes[i]) & (result['score'] >= corte_classes[i])] for i in range(len(ordem_classes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in certos:\n",
    "    #result[result['class'] == x].to_csv(x+\".csv\", index = False)\n",
    "    if(len(x['class'].unique()) >= 1):\n",
    "        x.to_excel(\"resultados/\" + x['class'].unique()[0] + \".xlsx\",index = False, header = True)\n",
    "        x.to_csv(\"resultados/\" + x['class'].unique()[0] + \".csv\",index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"saida_lstm_model_10\"\n",
    "\n",
    "class_dim = 3\n",
    "k = 10\n",
    "\n",
    "#number of iteractions \n",
    "epochs = 10 \n",
    "batch_size = 256\n",
    "training_size = 1\n",
    "#max number of words in embedding\n",
    "embed_dim = 512\n",
    "lstm_out_dim = 256\n",
    "top_words = 7500\n",
    "sentiment = []\n",
    "text = []\n",
    "lstm_input = []\n",
    "####\n",
    "file_out = open(output_file, 'w')\n",
    "######\n",
    "\n",
    "with open(dado_entrada_lstm_c) as file:\n",
    "    lstm_input_data1 = [x.split(\"\\t\") for x in file.read().split(\"\\n\")]\n",
    "size1 = len(lstm_input_data1)\n",
    "with open(dado_entrada_lstm_e) as file:\n",
    "    lstm_input_data2 = next_n_lines(file, size1)\n",
    "    \n",
    "size2 = len(lstm_input_data2)\n",
    "lstm_input_data = lstm_input_data1 + lstm_input_data2\n",
    "size = len(lstm_input_data)\n",
    "print(size1, size2, size)\n",
    "for i in range(size):\n",
    "    lstm_input.append([ lstm_input_data[i][0] , re.sub(' +',' ',re.sub(\"[^a-zA-Z 0-9;á-Ź]+\", \" \", str(lstm_input_data[i]))).split(\";\")])\n",
    "    sentiment.append(lstm_input[i][0])\n",
    "    text.append(lstm_input[i][1])\n",
    "tokenizer = Tokenizer(num_words = top_words, split = ' ')\n",
    "tokenizer.fit_on_texts(text)\n",
    "X = tokenizer.texts_to_sequences(text)\n",
    "X_train = X\n",
    "Y_train = sentiment\n",
    "folds = list(StratifiedKFold(n_splits=k, shuffle=True, random_state=1).split(X, sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = pad_sequences(X).shape[1]\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embed_dim,input_length = shape))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out_dim, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(class_dim, activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(X)\n",
    "Y = pd.get_dummies(sentiment).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = (1-training_size), random_state = 42)\n",
    "model.fit(X_train, Y_train, epochs = epochs, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dado_saida_d) as file:\n",
    "    lstm_teste = [x.split(\"\\t\") for x in file.read().split(\"\\n\")]\n",
    "size = len(lstm_teste)\n",
    "sentiment_test = []\n",
    "text_test = []\n",
    "lstm_input_test = []\n",
    "for i in range(size - 1):\n",
    "    lstm_input_test.append([ lstm_teste[i][0] , re.sub(' +',' ',re.sub(\"[^a-zA-Z 0-9;á-Ź]+\", \" \", str(lstm_teste[i]))).split(\";\")])\n",
    "    sentiment_test.append(lstm_input_test[i][0])\n",
    "    text_test.append(lstm_input_test[i][1])\n",
    "\n",
    "#tokenizer.fit_on_texts(text_test)\n",
    "X = tokenizer.texts_to_sequences(text_test)\n",
    "X = pad_sequences(X, maxlen=12)\n",
    "X_test = X\n",
    "Y_test = sentiment_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
