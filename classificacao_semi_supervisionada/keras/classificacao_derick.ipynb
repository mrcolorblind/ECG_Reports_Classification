{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importando pacotes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz \n",
    "from fuzzywuzzy import process\n",
    "from fuzzyJoao import partial_ratio\n",
    "from argparse import ArgumentParser\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from IPython.display import clear_output, display\n",
    "from nltk.util import ngrams\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, SpatialDropout1D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "import multiprocessing\n",
    "import time\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corte_classes = [84, 85, 96, 84, 97, 94, 81, 100, 83, 95, 83, 83, 81, 92, 95, 81, 85, 92, 84, 83, 86, 89, 83, 92, 93, 92, 83, 83, 87, \n",
    "                100, 92, 80, 84, 87, 91, 84, 100, 81, 100, 100, 88, 100, 81, 90, 100, 83, 90, 81, 86, 83, 96, 82, 97, 85, 90, 81, 81, 97,\n",
    "                95, 97, 84, 81, 84, 89, 86, 89, 83, 95]\n",
    "ordem_classes = ['Sobrecarga ventricular esquerda (critérios de Romhilt-Estes)',\n",
    " 'Sobrecarga atrial esquerda', 'Sobrecarga biventricular',\n",
    " 'Corrente de lesão subendocárdica', 'Bloqueio atrioventricular 2:1',\n",
    " 'Bloqueio atrioventricular total', 'Bloqueio atrioventricular de 1° grau',\n",
    " 'Sobrecarga ventricular esquerda( critérios de voltagem)',\n",
    " 'ECG dentro dos limites da normalidade para idade e sexo ',\n",
    " 'Sobrecarga biatrial', 'Possível inversão de posicionamento de eletrodos',\n",
    " 'Extrassístoles supraventriculares', 'Desvio do eixo do QRS para esquerda',\n",
    " 'Taquicardia supraventricular ', 'Taquicardia sinusal',\n",
    " 'área eletricamente inativa', 'Bradicardia sinusal', 'Pausa sinusal',\n",
    " 'Sobrecarga atrial direita', 'Bloqueio de ramo direito',\n",
    " 'Extrassístoles ventriculares' ,'Intervalo QT prolongado',\n",
    " 'Arritmia sinusal', 'Dextrocardia ', 'Flutter atrial',\n",
    " 'Bloqueio de ramo esquerdo',\n",
    " 'Alterações primárias da repolarização ventricular ',\n",
    " 'Isquemia subendocárdica', 'Ritmo juncional',\n",
    " 'Sobrecarga ventricular direita', 'Bloqueio atrioventricular avançado',\n",
    " 'Bloqueio divisional posteroinferior do ramo esquerdo',\n",
    " 'Sobrecarga ventricular esquerda (critérios de voltagem)',\n",
    " 'Bloqueio atrioventricular de 2° grau Mobitz I',\n",
    " 'Bloqueio atrioventricular de 2° grau Mobitz II',\n",
    " 'Pré-excitação ventricular tipo Wolff-Parkinson-White',\n",
    " 'Sistema de estimulação cardíaca normofuncionante',\n",
    " 'Alterações da repolarização ventricular atribuídas à ação digitálica',\n",
    " 'Bloqueio de ramo direito e bloqueio divisional  posteroinferior do ramo esquerdo',\n",
    " 'Progressão lenta de R nas derivações precordiais ',\n",
    " 'Corrente de lesão subepicárdica - provável infarto agudo do miocárdio com supradesnivelamento de ST',\n",
    " 'Suspeita de Síndrome de  Brugada, repetir V1-V2 em derivações superiores',\n",
    " 'Desvio do eixo do QRS para direita', 'Ritmo atrial ectópico',\n",
    " 'Intervalo PR curto', 'Ritmo atrial multifocal',\n",
    " 'Sistema de estimulação cardíaca com disfunção',\n",
    " 'Bloqueio divisional anterossuperior do ramo esquerdo',\n",
    " 'Distúrbio de condução do ramo direito', 'Taquicardia atrial',\n",
    " 'Batimento de escape atrial','Fibrilação atrial',\n",
    " 'Taquicardia ventricular não sustentada',\n",
    " 'Taquicardia ventricular sustentada',\n",
    " 'Bloqueio de ramo direito e bloqueio divisional anterossuperior do ramo esquerdo',\n",
    " 'Batimento de escape supraventricular', 'Batimento de escape ventricular ',\n",
    " 'Batimento de escape juncional', 'Taquicardia juncional',\n",
    " 'Taquicardia atrial multifocal ', 'Corrente de lesão subepicárdica',\n",
    " 'Alterações inespecíficas da repolarização ventricular',\n",
    " 'Alterações secundárias da repolarização ventricular',\n",
    " 'Distúrbio de condução do ramo esquerdo', 'Repolarização precoce',\n",
    " 'Ausência de sinal eletrocardiográfico que impede a análise',\n",
    " 'Traçado com qualidade técnica insuficiente', 'Síndrome de Brugada']\n",
    "##observações\n",
    "##1 - bav1, regra para excluir todos que não forem \"primeiro grau\", cerca de 80 falsos positivos com a nota de corte 81\n",
    "##2 - problema no \"sve critérios de voltagem\" (aparece 2 vezes, verificar) - cuidado com \"(\" no dicionário\n",
    "##3 - problema no ritmo juncional\n",
    "##4 - char estranho para mobitz I e II (33, 34)\n",
    "##5 - padrão vazio para Sistema de estimulação cardíaca normofuncionante (36)\n",
    "##6 - problema crase Alterações da repolarização ventricular atribuídas à ação digitálica (37)\n",
    "##7 - padrão vazio para Bloqueio de ramo direito e bloqueio divisional  posteroinferior do ramo esquerdo (38)\n",
    "##8 - padrão vazio para Progressão lenta de R nas derivações precordiais (39)\n",
    "##9 - padrão vazio para Corrente de lesão subepicárdica - provável infarto agudo do miocárdio com supradesnivelamento de ST (40)\n",
    "##10 - padrão vazio para (41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_texto = pd.read_csv(\"/scratch/derickmath/text_processing/2006-2010/exames_texto_txt.csv\")\n",
    "dicionario = pd.read_csv(\"/scratch/derickmath/text_processing/2006-2010/DicionarioECG.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### print(len(dados_texto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time parallel for 200 lines = 123.9019660949707\n",
    "\n",
    "time sequential for 200 lines = 3.2906479835510254"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-06741cc4597b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtime100it\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdados_texto\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conteudo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"aux.rtf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/scratch/derickmath/text_processing/2006-2010/runrtf.sh\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"aux.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"UTF-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ls\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-l\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \"\"\"\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    767\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    770\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1445\u001b[0m                             \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m                             \u001b[0merrpipe_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrpipe_write\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1447\u001b[0;31m                             restore_signals, start_new_session, preexec_fn)\n\u001b[0m\u001b[1;32m   1448\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_child_created\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "text = []\n",
    "for i in range(len(dados_texto[\"conteudo\"])):\n",
    "    time100it = time.time()\n",
    "    print(dados_texto['conteudo'][i], file=open(\"aux.rtf\", \"w\"))\n",
    "    sh = subprocess.call([\"sh\", \"/scratch/derickmath/text_processing/2006-2010/runrtf.sh\"])\n",
    "    file = open(\"aux.txt\", encoding=\"UTF-8\")\n",
    "    text.append(file.read())\n",
    "    clear_output(wait=True)\n",
    "    if(i%100 == 0):\n",
    "        print(\"it = \", i, len(dados_texto['conteudo']), i/len(dados_texto['conteudo']))\n",
    "        print(\"time = \", time.time() - start_time)\n",
    "        print(\"100 it time = \", time.time() - time100it)\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-286438491d48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdados_texto\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"conteudo_txt\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdados_texto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/scratch/derickmath/code/2006-2010/exames_texto_txt__.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "dados_texto[\"conteudo_txt\"] = text\n",
    "dados_texto.to_csv('/scratch/derickmath/code/2006-2010/exames_texto_txt__.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_texto = pd.read_csv(\"/scratch/derickmath/code/2006-2010/exames_texto_txt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função que recebe o dicionário e uma String e retorna uma lista com a similaridade de cada doença à String\n",
    "def checarSimilaridadeDoencas(texto, dicionario, id_evento):\n",
    "    listaScore = []\n",
    "    for row in dicionario.itertuples():\n",
    "        maiorScore = 0\n",
    "        maiorScoreL = []\n",
    "        for diag in row:\n",
    "            if ((type(diag) is not int and type(diag) is not float) and (type(texto) is not float)):\n",
    "                score = partial_ratio(diag.lower(), texto.lower())\n",
    "                if score[3] > maiorScore: \n",
    "                    maiorScore = score[3]\n",
    "                    maiorScoreL = score\n",
    "        if (maiorScore > 60):\n",
    "            listaScore.append([id_evento, row[1], maiorScoreL[0], maiorScoreL[1], maiorScoreL[2], maiorScoreL[3], texto])\n",
    "#         else:\n",
    "#             listaScore.append([id_evento, row[1], maiorScoreL[0], maiorScoreL[1], maiorScoreL[2], maiorScoreL[3], texto])\n",
    "    return listaScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.653634548187256\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "start_time = time.time()\n",
    "resultados_match_p = Parallel(n_jobs = num_cores)(delayed(checarSimilaridadeDoencas)\n",
    "                              (str(dados_texto['conteudo_txt'][i]).translate(str.maketrans('', '', string.punctuation)), dicionario, dados_texto['id'][i])\n",
    "                    for i in range(40))\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(dados_texto['conteudo_txt'])\n",
    "# len(dicionario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = multiprocessing.cpu_count()\n",
    "start_time = time.time()\n",
    "resultados_match_p = Parallel(n_jobs = num_cores)(delayed(checarSimilaridadeDoencas)\n",
    "                              (str(dados_texto['conteudo_txt'][i]).translate(str.maketrans('', '', string.punctuation)), dicionario, dados_texto['id'][i])\n",
    "                    for i in range(len(dados_texto['conteudo_txt'])))\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### result = []\n",
    "resultado_n_vazio = [resultados_match_p[x] for x in range(len(resultados_match_p)) if resultados_match_p[x] != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for x in resultado_n_vazio:\n",
    "    for y in x:\n",
    "        result.append(y)\n",
    "result = pd.DataFrame(result,columns = [\"id\", \"class\", \"inicio\", \"fim\", \"trecho\", \"score\", \"texto\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_vazio = [resultados_match_p[x] for x in range(len(resultados_match_p)) if resultados_match_p[x] == []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trecho               score\n",
       " sndrome de brugada  95       10\n",
       "sindrome de brugada  95        1\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[(result['class'] == ordem_classes[-1]) & (result['score'] <= 100) & (result['score'] >= 80)].groupby([\"trecho\", \"score\"]).id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "certos = [result[(result['class'] == ordem_classes[i]) & (result['score'] >= corte_classes[i])] for i in range(len(ordem_classes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in certos:\n",
    "    #result[result['class'] == x].to_csv(x+\".csv\", index = False)\n",
    "    if(len(x['class'].unique()) >= 1):\n",
    "        x.to_excel(\"resultados2/\" + x['class'].unique()[0] + \".xlsx\",index = False, header = True)\n",
    "        x.to_csv(\"resultados2/\" + x['class'].unique()[0] + \".csv\",index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASSIFICAÇÃO SUPERVISIONADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ids = pd.read_csv('diff_ids')\n",
    "ids_achados = pd.read_csv('ids_achados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pos/derickmath/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/pos/derickmath/miniconda3/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "dados_validacao = dados_texto[dados_texto['id'].isin(diff_ids['id'])]\n",
    "dados_treino = dados_texto[dados_texto['id'].isin(ids_achados['id'])]\n",
    "classes = []\n",
    "for x in ordem_classes:\n",
    "    if(os.path.isfile(\"resultados2/\" + x + \".csv\")):\n",
    "        dados_treino[x] = 0\n",
    "for x in ordem_classes:\n",
    "    if(os.path.isfile(\"resultados2/\" + x + \".csv\")):\n",
    "        classes.append(x)\n",
    "        readf = pd.read_csv('resultados2/' + x + \".csv\")\n",
    "        dados_treino.set_value(dados_treino['id'].isin(readf['id']),x,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max number of words in embedding\n",
    "embed_dim = 512\n",
    "lstm_out_dim = 256\n",
    "top_words = 7500\n",
    "\n",
    "text = dados_treino['conteudo_txt']\n",
    "labels = dados_treino[classes]\n",
    "\n",
    "class_dim = 3\n",
    "k = 3\n",
    "text = [re.sub(\"[^a-zA-Z 0-9;á-Ź]+\", \" \", str(t)) for t in text]\n",
    "#text = [[x for x in t.split(\" \")] for t in text if x != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = top_words, split = ' ')\n",
    "tokenizer.fit_on_texts(text)\n",
    "X = tokenizer.texts_to_sequences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 327, 512)          3840000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 327, 512)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               787456    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 63)                16191     \n",
      "=================================================================\n",
      "Total params: 4,643,647\n",
      "Trainable params: 4,643,647\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#number of iteractions\n",
    "epochs = 30 \n",
    "batch_size = 256\n",
    "\n",
    "shape = pad_sequences(X).shape[1]\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embed_dim,input_length = shape))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out_dim, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(63, activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pos/derickmath/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "X = pad_sequences(X)\n",
    "model.fit(X, labels, epochs = epochs, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dado_saida_d) as file:\n",
    "    lstm_teste = [x.split(\"\\t\") for x in file.read().split(\"\\n\")]\n",
    "size = len(lstm_teste)\n",
    "sentiment_test = []\n",
    "text_test = []\n",
    "lstm_input_test = []\n",
    "for i in range(size - 1):\n",
    "    lstm_input_test.append([ lstm_teste[i][0] , re.sub(' +',' ',re.sub(\"[^a-zA-Z 0-9;á-Ź]+\", \" \", str(lstm_teste[i]))).split(\";\")])\n",
    "    sentiment_test.append(lstm_input_test[i][0])\n",
    "    text_test.append(lstm_input_test[i][1])\n",
    "\n",
    "#tokenizer.fit_on_texts(text_test)\n",
    "X = tokenizer.texts_to_sequences(text_test)\n",
    "X = pad_sequences(X, maxlen=12)\n",
    "X_test = X\n",
    "Y_test = sentiment_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "classes = []\n",
    "for x in ordem_classes:\n",
    "    if(os.path.isfile(\"resultados_lstm/\" + x + \".csv\")):\n",
    "        dados_texto[x] = 0\n",
    "for x in ordem_classes:\n",
    "    if(os.path.isfile(\"resultados_lstm/\" + x + \".csv\")):\n",
    "        classes.append(x)\n",
    "        readf = pd.read_csv('resultados_lstm/' + x + \".csv\")\n",
    "        dados_texto.set_value(dados_texto['id'].isin(readf['id']),x,1)\n",
    "for x in ordem_classes:\n",
    "    if(os.path.isfile(\"resultados2/\" + x + \".csv\")):\n",
    "        readf = pd.read_csv('resultados2/' + x + \".csv\")\n",
    "        dados_texto.set_value(dados_texto['id'].isin(readf['id']),x,1)\n",
    "print(len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0506712201352158"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dados_texto[dados_texto['Taquicardia atrial'] == 1])/len(dados_texto)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dados_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-dfc6d8b2fc80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdados_texto\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdados_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'conteudo_txt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resultados_final/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dados_text' is not defined"
     ]
    }
   ],
   "source": [
    "for x in classes:\n",
    "    dados_texto[dados_texto[x] == 1][['id', 'conteudo_txt']].to_csv(\"resultados_final/\" + x + \".csv\",index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
