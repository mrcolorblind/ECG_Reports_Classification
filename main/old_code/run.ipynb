{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modules, classes and methods...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading modules, classes and methods...\")\n",
    "import multiprocessing\n",
    "from unidecode import unidecode\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torchvision\n",
    "import pickle\n",
    "from unicodedata import normalize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from torchvision import transforms, datasets\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import matplotlib.pyplot as plt\n",
    "from argparse import ArgumentParser\n",
    "import textclassification as tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLOBAL VARIABLES\n",
    "N_CORES = multiprocessing.cpu_count()\n",
    "\n",
    "#Scores\n",
    "STARTING         = 0\n",
    "ENDING           = 2000000\n",
    "BATCH_SCORES     = 10000\n",
    "\n",
    "#Neural Network\n",
    "TOP_WORDS       = 10000\n",
    "REBUILD_DATA    = True\n",
    "BIDIRECTIONAL   = True\n",
    "EPOCHS          = 30\n",
    "BATCH_SIZE      = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Cutting slice. From 0 to 2000000...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "\n",
    "valid = np.load(\"../light_data/new_classes.npy\")\n",
    "prevalences = pd.read_csv(\"../light_data/prevalencia_e_scores_com_siglas.csv\")\n",
    "dicionarioCsv = pd.read_csv(\"../light_data/DicionarioECG_completo.csv\", index_col = 0)\n",
    "siglasCsv = pd.read_csv(\"../light_data/DicionarioECG_Siglas.csv\", index_col = 0)\n",
    "db = pd.read_csv(\"../../data/DATA_LAUDOS_TEXTO_formato1\", sep = \";\")\n",
    "\n",
    "\n",
    "print(\"Cutting slice. From {} to {}...\".format(STARTING, ENDING))\n",
    "db = db[STARTING:ENDING]\n",
    "db = db.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dicionarioCsv = pd.read_csv(\"../light_data/DicionarioECG_completo.csv\", index_col = 0)\n",
    "dicionario = {}\n",
    "for row in dicionarioCsv.itertuples():\n",
    "    aux = []\n",
    "    for diag in row:\n",
    "        if type(diag) is str: aux.append(\" \" + diag + \" \")\n",
    "    dicionario[row[0]] = aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing texts...\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing texts...\")\n",
    "texts = [\" \" + tc.clean_text(text) + \" \" for text in db[\"CONTEUDO\"]]\n",
    "\n",
    "siglas = {}\n",
    "for row in siglasCsv.itertuples():\n",
    "    aux = []\n",
    "    for diag in row:\n",
    "        if type(diag) is str: aux.append(\" \" + diag + \" \")\n",
    "    siglas[row[0]] = aux\n",
    "siglas[11].append(\" bav2:1 \")\n",
    "    \n",
    "dicionario = {}\n",
    "for row in dicionarioCsv.itertuples():\n",
    "    aux = []\n",
    "    for diag in row:\n",
    "        if type(diag) is str: aux.append(diag)\n",
    "    dicionario[row[0]] = aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores...\n",
      "\n",
      "Working in batches of 100\n",
      "0 / 1000000\n",
      "This batch has been done in 0 minutes and 3.968424081802368 seconds!\n",
      "Expected time for ending is around 11 hours and  1 minutes!\n",
      "100 / 1000000\n",
      "This batch has been done in 0 minutes and 3.566516399383545 seconds!\n",
      "Expected time for ending is around 10 hours and  28 minutes!\n",
      "200 / 1000000\n",
      "This batch has been done in 0 minutes and 3.5585811138153076 seconds!\n",
      "Expected time for ending is around 10 hours and  16 minutes!\n",
      "300 / 1000000\n",
      "This batch has been done in 0 minutes and 3.494030714035034 seconds!\n",
      "Expected time for ending is around 10 hours and  7 minutes!\n",
      "400 / 1000000\n",
      "This batch has been done in 0 minutes and 3.689072370529175 seconds!\n",
      "Expected time for ending is around 10 hours and  9 minutes!\n",
      "500 / 1000000\n",
      "This batch has been done in 0 minutes and 3.4898159503936768 seconds!\n",
      "Expected time for ending is around 10 hours and  4 minutes!\n",
      "600 / 1000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-205-a664ae163945>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     scores = Parallel(n_jobs = N_CORES)(delayed(return_scores)\n\u001b[1;32m     16\u001b[0m                               \u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdicionario\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                     for text in texts[i:i+batch])\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtotalScores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    552\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Calculating scores...\\n\")\n",
    "\n",
    "def return_scores(text, dicionario):\n",
    "    scores = [max([tc.make_score(text, diag) for diag in dicionario[i]]) if valid[i][1] else 0 for i in range(74)]\n",
    "    return scores\n",
    "\n",
    "batch = BATCH_SCORES\n",
    "print(\"Working in batches of\", batch)\n",
    "with open('../../data/resultados/'+ SCORES_FILE_NAME, 'w') as f:\n",
    "    f.write(\"id_exame, scorings\\n\")\n",
    "    #     errors = []\n",
    "\n",
    "    \n",
    "startTime = time.time()\n",
    "for i in range(0, len(db), batch):\n",
    "    print(i,\"/\",len(db))\n",
    "    startBatch = time.time()\n",
    "    #try:\n",
    "#     scores = [return_scores(text, dicionario) for text in texts[i:i+batch]]\n",
    "    scores = Parallel(n_jobs = N_CORES)(delayed(return_scores)\n",
    "                              (text, dicionario)\n",
    "                    for text in texts[i:i+batch])\n",
    "    \n",
    "    if(i == 0): result = np.array(scores)\n",
    "    else: result = np.concatenate((totalScores, np.array(scores)), axis = 0)\n",
    "    with open('../../data/resultados/' + SCORES_FILE_NAME, 'a') as f:\n",
    "        for j in range(i,i+batch):\n",
    "            f.write(str(db[\"ID_EXAME\"][j]))\n",
    "            f.write(',\"')\n",
    "            f.write(str(scores[j-i]))\n",
    "            f.write('\"\\n')\n",
    "#     except:\n",
    "#         print(\"ERROR!!!!!\")\n",
    "#         errors.append([i, i+batch])\n",
    "#     errors = np.array(errors)\n",
    "#     np.save(\"errors.npy\", errors)\n",
    "    \n",
    "    expectedTime = (((time.time() - startTime)/(i+batch)) * (len(db))) - (time.time() - startTime)\n",
    "    timeBatch    = time.time() - startBatch\n",
    "    print(\"This batch has been done in\", int(timeBatch/60), \"minutes and\", timeBatch%60,\"seconds!\")\n",
    "    print(\"Expected time for ending is around\", int(expectedTime/3600), \"hours and \", int((expectedTime%3600)/60),\"minutes!\")\n",
    "#         with open('../../data/resultados/scorings1.csv', 'a') as f:\n",
    "#             for j in range(i,i+batch):\n",
    "#                 f.write(str(db[\"ID_EXAME\"][j]))\n",
    "#                 f.write(',\"')\n",
    "#                 f.write(str(scores[j-i]))\n",
    "#                 f.write('\"\\n')\n",
    "print(\"Y of training data defined!!! Saving...\")\n",
    "np.save(\"output/score_values.npy\", result)\n",
    "print(\"Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.load(\"output/score_values.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['área eletricamente inativa',\n",
       "  'zona eletricamente inativa',\n",
       "  'infarto prévio',\n",
       "  'IAM prévio',\n",
       "  'fibrose',\n",
       "  'inatividade elétrica',\n",
       "  'zona inativa',\n",
       "  'área inativa',\n",
       "  'ondas q patológicas'],\n",
       " 1: ['Bloqueio de ramo direito#', 'Bloqueio do ramo direito#', 'BRD!'],\n",
       " 2: ['Bloqueio de ramo esquerdo#', 'Bloqueio do ramo esquerdo'],\n",
       " 3: ['Bloqueio de ramo direito e bloqueio divisional anterossuperior do ramo esquerdo',\n",
       "  'bloqueio de ramo direito e hemibloqueio anterior esquerdo',\n",
       "  'bloqueio de ramo direito e bloqueio anterossuperior do ramo esquerdo',\n",
       "  'BRD e BDAS',\n",
       "  'BRD e BDASE',\n",
       "  'BRD e HBAE'],\n",
       " 4: ['Bloqueio intraventricular inespecífico', 'BIV?'],\n",
       " 5: ['Sobrecarga ventricular esquerda (critérios de Romhilt-Estes)',\n",
       "  'padrão strain',\n",
       "  'Hipertrofia ventricular esquerda',\n",
       "  'Sobrecarga ventricular esquerda'],\n",
       " 6: ['Sobrecarga ventricular esquerda (critérios de voltagem)',\n",
       "  'Sokolow Lyon'],\n",
       " 7: ['Fibrilação atrial', 'Fibrilação auricular'],\n",
       " 8: ['Flutter atrial', 'Flutter auricular'],\n",
       " 9: ['Bloqueio atrioventricular de 2° grau Mobitz I#',\n",
       "  'BAV 2º grau do tipo Wenckebach#',\n",
       "  'BAV 2º grau Mobitz I#',\n",
       "  'Wenckebach',\n",
       "  'do tipo mobitz i#',\n",
       "  'Bloqueio atrioventricular de segundo grau Mobitz I#',\n",
       "  'BAV segundo grau do tipo mobitz i#',\n",
       "  'bloqueio av segundo grau mobitz i#'],\n",
       " 10: ['Bloqueio atrioventricular de 2° grau Mobitz II',\n",
       "  'BAV 2º grau Mobitz II'],\n",
       " 11: ['Bloqueio atrioventricular 2:1', 'BAV 2:1'],\n",
       " 12: ['Bloqueio atrioventricular avançado', 'BAV avançado', 'BAV 3º grau'],\n",
       " 13: ['Bloqueio atrioventricular total', 'BAVT!'],\n",
       " 14: ['Pré-excitação ventricular tipo Wolff-Parkinson-White',\n",
       "  'Pré excitação ventricular',\n",
       "  'via acessória',\n",
       "  'via anômala',\n",
       "  'Wolf Parkinson White'],\n",
       " 15: ['Sistema de estimulação cardíaca normofuncionante',\n",
       "  'Marcapasso sem disfunção',\n",
       "  'Ressincronizador cardíaco  sem disfunção',\n",
       "  'Cardiodesfibrilador sem disfunção',\n",
       "  'Marcapasso artificial sem disfunção',\n",
       "  'Marcapasso dupla câmara sem disfunção',\n",
       "  'Marcapasso ventricular sem disfunção'],\n",
       " 16: ['Sistema de estimulação cardíaca com disfunção',\n",
       "  'Marcapasso com disfunção',\n",
       "  'Ressincronizador cardíaco com disfunção',\n",
       "  'Cardiodesfibrilador com disfunção',\n",
       "  'Marcapasso artificial com disfunção',\n",
       "  'Marcapasso dupla câmara com disfunção',\n",
       "  'Marcapasso ventricular com disfunção'],\n",
       " 17: ['Taquicardia atrial multifocal#'],\n",
       " 18: ['Taquicardia atrial#'],\n",
       " 19: ['Taquicardia supraventricular#',\n",
       "  'Taquicardia paroxística supraventricular#',\n",
       "  'Taquicardia por reentrada nodal#',\n",
       "  'Taquicardia atrioventricular#'],\n",
       " 20: ['Corrente de lesão subendocárdica', 'Infradesnivelamento de ST'],\n",
       " 21: ['Alterações primárias da repolarização ventricular#',\n",
       "  'Isquemia subepicárdica#'],\n",
       " 22: ['Extrassístoles supraventriculares#',\n",
       "  'Extrassístoles atriais#',\n",
       "  'Ectopia atrial',\n",
       "  'Ectopia supraventricular'],\n",
       " 23: ['Extrassístoles ventriculares#', 'Ectopia ventricular#'],\n",
       " 24: ['Bradicardia sinusal#'],\n",
       " 25: ['ECG dentro dos limites da normalidade para idade e sexo',\n",
       "  'eletrocardiograma normal',\n",
       "  'ECG normal',\n",
       "  'eletrocardiograma dentro dos limites da normalidade para idade e sexo',\n",
       "  'Traçado dentro da normalidade',\n",
       "  'ECG dentro dos limites da normalidade',\n",
       "  'eletrocardiograma dentro dos limites da normalidade'],\n",
       " 26: ['Alterações da repolarização ventricular atribuídas à ação digitálica',\n",
       "  'Alterações da repolarização ventricular pelo uso de digital',\n",
       "  'Alterações da repolarização ventricular pela digoxina'],\n",
       " 27: ['Alterações inespecíficas da repolarização ventricular#'],\n",
       " 28: ['Alterações secundárias da repolarização ventricular#'],\n",
       " 29: ['Arritmia sinusal', 'Arritmia sinusal fásica'],\n",
       " 30: ['Ausência de sinal eletrocardiográfico que impede a análise',\n",
       "  'ausência de traçado'],\n",
       " 31: ['Interferência na linha de base que não impede a análise do ECG'],\n",
       " 32: ['Ausência de sinal eletrocardiográfico que não impede a análise'],\n",
       " 33: ['Traçado com qualidade técnica insuficiente', 'traçado com ruido'],\n",
       " 34: ['Possível inversão de posicionamento de eletrodos',\n",
       "  'troca de eletrodos',\n",
       "  'inversão de eletrodos'],\n",
       " 35: ['Baixa voltagem em derivações precordiais#'],\n",
       " 36: ['Baixa voltagem em derivações periféricas#'],\n",
       " 37: ['Bloqueio atrioventricular de 1 grau#',\n",
       "  'BAV de 1 grau#',\n",
       "  'bloqueio av de 1 grau#',\n",
       "  'bloqueio atrioventricular de primeiro grau#',\n",
       "  'bloqueio av de primeiro grau#',\n",
       "  'bav de primeiro grau#'],\n",
       " 38: ['Bloqueio de ramo direito e bloqueio divisional  posteroinferior do ramo esquerdo',\n",
       "  'BRD e BDPI',\n",
       "  'bloqueio de ramo direito e hemibloqueio posterior esquerdo',\n",
       "  'bloqueio de ramo direito e bloqueio posteroinferior esquerdo',\n",
       "  'BRD e HBPE',\n",
       "  'BRD e BDPIE'],\n",
       " 39: ['Bloqueio divisional anterossuperior do ramo esquerdo',\n",
       "  'Hemibloqueio anterior esquerdo',\n",
       "  'hemibloqueio anterossuperior esquerdo',\n",
       "  'bloqueio divisional anterossuperior',\n",
       "  'BDASE!',\n",
       "  'BDAS!',\n",
       "  'HBAE!'],\n",
       " 40: ['Bloqueio divisional posteroinferior esquerdo',\n",
       "  'bloqueio posteroinferior esquerdo',\n",
       "  'Bloqueio divisional posteroinferior ramo esquerdo'],\n",
       " 41: ['Desvio do eixo do QRS para direita#',\n",
       "  'Eixo desviado para direita#',\n",
       "  'Eixo QRS para direita#',\n",
       "  'desvio do qrs para esquerda#',\n",
       "  'desvio qrs direita#',\n",
       "  'desvio de eixo eletrico para direita#'],\n",
       " 42: ['Desvio do eixo do QRS para esquerda#',\n",
       "  'Eixo desviado para esquerda#',\n",
       "  'Eixo QRS para esquerda#',\n",
       "  'desvio do qrs para direita#',\n",
       "  'desvio qrd esquerda#',\n",
       "  'desvio de eixo eletrico para direito#'],\n",
       " 43: ['Dissociação atrioventricular isorrítmica'],\n",
       " 44: ['Distúrbio de condução do ramo direito',\n",
       "  'Atraso da condução pelo ramo direito'],\n",
       " 45: ['Distúrbio de condução do ramo esquerdo#',\n",
       "  'Atraso da condução pelo ramo esquerdo#'],\n",
       " 46: ['Intervalo PR curto#'],\n",
       " 47: ['Intervalo QT prolongado', 'QT longo'],\n",
       " 48: ['Isquemia subendocárdica#', 'Ondas T apiculadas'],\n",
       " 49: ['Progressão lenta de R nas derivações precordiais#',\n",
       "  'Diminuição de forças septais',\n",
       "  'diminuicao de forcas antero septais',\n",
       "  'Má progressão de R nas derivações precordiais#'],\n",
       " 50: ['Pausa sinusal', 'Parada sinusal', 'Bloqueio sinoatrial'],\n",
       " 51: ['Corrente de lesão subepicárdica', 'Pericardite'],\n",
       " 52: ['Corrente de lesão subepicárdica - provável infarto agudo do miocárdio com supradesnivelamento de ST',\n",
       "  'Provável infarto agudo do miocárdio com supradesnivelamento do segmento ST',\n",
       "  'IAM com supra ST'],\n",
       " 53: ['Repolarização precoce'],\n",
       " 54: ['Ritmo atrial ectópico'],\n",
       " 55: ['Ritmo atrial multifocal'],\n",
       " 56: ['Ritmo idioventricular acelerado'],\n",
       " 57: ['Ritmo juncional', 'Ritmo juncional ativo'],\n",
       " 58: ['Síndrome de Brugada'],\n",
       " 59: ['Sobrecarga atrial direita', 'Hipertrofia atrial direita'],\n",
       " 60: ['Sobrecarga atrial esquerda', 'Hipertrofia atrial esquerda'],\n",
       " 61: ['Sobrecarga biatrial', 'Hipertrofia biatrial'],\n",
       " 62: ['Sobrecarga biventricular', 'Hipertrofia biventricular', 'SBV!'],\n",
       " 63: ['Sobrecarga ventricular direita',\n",
       "  'Hipertrofia ventricular direita',\n",
       "  'SVD!'],\n",
       " 64: ['Sobrecarga ventricular esquerda( critérios de voltagem)',\n",
       "  'Sobrecarga ventricular esquerda por critérios de Sokolow-Lyon',\n",
       "  'Sobrecarga ventricular esquerda por critérios de Lewis',\n",
       "  'Hipertrofia ventricular esquerda por critérios de Sokolow-Lyon',\n",
       "  'Hipertrofia ventricular esquerda por critérios de Lewis',\n",
       "  'Hipertrofia ventricular esquerda( critérios de voltagem)',\n",
       "  'Sokolow Lyon'],\n",
       " 65: ['Taquicardia sinusal#'],\n",
       " 66: ['Taquicardia ventricular não sustentada#', 'TVNS!'],\n",
       " 67: ['Taquicardia ventricular sustentada#', 'TVS!'],\n",
       " 68: ['Suspeita de Síndrome de  Brugada, repetir V1-V2 em derivações superiores',\n",
       "  'Brugada tipo 2',\n",
       "  'Padrão de Brugada'],\n",
       " 69: ['Taquicardia juncional#'],\n",
       " 70: ['Batimento de escape atrial'],\n",
       " 71: ['Batimento de escape supraventricular'],\n",
       " 72: ['Batimento de escape juncional'],\n",
       " 73: ['Batimento de escape ventricular']}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_scores(text, dicionario):\n",
    "    scores = [max([tc.make_score(text, diag) for diag in dicionario[i]])]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating scores...\\n\")\n",
    "\n",
    "def return_scores(text, dicionario):\n",
    "    scores = [max([tc.make_score(text, diag) for diag in dicionario[i]]) if valid[i][1] else 0 for i in range(74)]\n",
    "    return scores\n",
    "\n",
    "batch = BATCH_SCORES\n",
    "print(\"Working in batches of\", batch)\n",
    "with open('../../data/resultados/'+ SCORES_FILE_NAME, 'w') as f:\n",
    "    f.write(\"id_exame, scorings\\n\")\n",
    "    #     errors = []\n",
    "\n",
    "    \n",
    "startTime = time.time()\n",
    "for i in range(0, len(db), batch):\n",
    "    print(i,\"/\",len(db))\n",
    "    startBatch = time.time()\n",
    "    #try:\n",
    "#     scores = [return_scores(text, dicionario) for text in texts[i:i+batch]]\n",
    "    scores = Parallel(n_jobs = N_CORES)(delayed(return_scores)\n",
    "                              (text, dicionario)\n",
    "                    for text in texts[i:i+batch])\n",
    "    \n",
    "    if(i == 0): result = np.array(scores)\n",
    "    else: result = np.concatenate((totalScores, np.array(scores)), axis = 0)\n",
    "    with open('../../data/resultados/' + SCORES_FILE_NAME, 'a') as f:\n",
    "        for j in range(i,i+batch):\n",
    "            f.write(str(db[\"ID_EXAME\"][j]))\n",
    "            f.write(',\"')\n",
    "            f.write(str(scores[j-i]))\n",
    "            f.write('\"\\n')\n",
    "#     except:\n",
    "#         print(\"ERROR!!!!!\")\n",
    "#         errors.append([i, i+batch])\n",
    "#     errors = np.array(errors)\n",
    "#     np.save(\"errors.npy\", errors)\n",
    "    \n",
    "    expectedTime = (((time.time() - startTime)/(i+batch)) * (len(db))) - (time.time() - startTime)\n",
    "    timeBatch    = time.time() - startBatch\n",
    "    print(\"This batch has been done in\", int(timeBatch/60), \"minutes and\", timeBatch%60,\"seconds!\")\n",
    "    print(\"Expected time for ending is around\", int(expectedTime/3600), \"hours and \", int((expectedTime%3600)/60),\"minutes!\")\n",
    "#         with open('../../data/resultados/scorings1.csv', 'a') as f:\n",
    "#             for j in range(i,i+batch):\n",
    "#                 f.write(str(db[\"ID_EXAME\"][j]))\n",
    "#                 f.write(',\"')\n",
    "#                 f.write(str(scores[j-i]))\n",
    "#                 f.write('\"\\n')\n",
    "print(\"Y of training data defined!!! Saving...\")\n",
    "# np.save(\"output/score_values.npy\", result)\n",
    "print(\"Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating thresholds and creating binary arrays...\n",
      "Calculating for área_eletricamente_inativa\n",
      "Threshold = 88.889\n",
      "Calculating for Bloqueio_de_ramo_direito\n",
      "Threshold = 92.308\n",
      "Calculating for Bloqueio_de_ramo_esquerdo\n",
      "Threshold = 92.593\n",
      "Calculating for Sobrecarga_ventricular_esquerda_(critérios_de_Romhilt-Estes)\n",
      "Threshold = 93.939\n",
      "Calculating for Fibrilação_atrial\n",
      "Threshold = 78.947\n",
      "Calculating for Flutter_atrial\n",
      "Threshold = 93.75\n",
      "Calculating for Bloqueio_atrioventricular_de_2°_grau_Mobitz_I\n",
      "Threshold = 76.596\n",
      "Calculating for Pré-excitação_ventricular_tipo_Wolff-Parkinson-White\n",
      "Threshold = 77.778\n",
      "Calculating for Sistema_de_estimulação_cardíaca_normofuncionante\n",
      "Threshold = 62.162\n",
      "Calculating for Taquicardia_atrial_multifocal\n",
      "Threshold = 53.125\n",
      "Calculating for Taquicardia_supraventricular\n",
      "Threshold = 70.968\n",
      "Calculating for Alterações_primárias_da_repolarização_ventricular\n",
      "Threshold = 73.077\n",
      "Calculating for Extrassístoles_supraventriculares\n",
      "Threshold = 80.0\n",
      "Calculating for Extrassístoles_ventriculares\n",
      "Threshold = 33.333\n",
      "Calculating for Bradicardia_sinusal\n",
      "Threshold = 95.238\n",
      "Calculating for ECG_dentro_dos_limites_da_normalidade_para_idade_e_sexo\n",
      "Threshold = 74.074\n",
      "Calculating for Alterações_inespecíficas_da_repolarização_ventricular\n",
      "Threshold = 30.909\n",
      "Calculating for Alterações_secundárias_da_repolarização_ventricular\n",
      "Threshold = 88.679\n",
      "Calculating for Arritmia_sinusal\n",
      "Threshold = 88.889\n",
      "Calculating for Ausência_de_sinal_eletrocardiográfico_que_impede_a_análise\n",
      "Threshold = 85.714\n",
      "Calculating for Possível_inversão_de_posicionamento_de_eletrodos\n",
      "Threshold = 95.0\n",
      "Calculating for Bloqueio_atrioventricular_de_1°_grau\n",
      "Threshold = 50.0\n",
      "Calculating for Bloqueio_divisional_anterossuperior_do_ramo_esquerdo\n",
      "Threshold = 68.519\n",
      "Calculating for Bloqueio_divisional_posteroinferior_do_ramo_esquerdo\n",
      "Threshold = 70.37\n",
      "Calculating for Desvio_do_eixo_do_QRS_para_direita\n",
      "Threshold = 77.778\n",
      "Calculating for Desvio_do_eixo_do_QRS_para_esquerda\n",
      "Threshold = 78.378\n",
      "Calculating for Distúrbio_de_condução_do_ramo_direito\n",
      "Threshold = 76.923\n",
      "Calculating for Distúrbio_de_condução_do_ramo_esquerdo\n",
      "Threshold = 87.5\n",
      "Calculating for Intervalo_PR_curto\n",
      "Threshold = 45.0\n",
      "Calculating for Intervalo_QT_prolongado\n",
      "Threshold = 45.455\n",
      "Calculating for Isquemia_subendocárdica\n",
      "Threshold = 88.0\n",
      "Calculating for Progressão_lenta_de_R_nas_derivações_precordiais\n",
      "Threshold = 45.098\n",
      "Calculating for Ritmo_atrial_ectópico\n",
      "Threshold = 43.478\n",
      "Calculating for Sobrecarga_atrial_esquerda\n",
      "Threshold = 44.828\n",
      "Calculating for Taquicardia_sinusal\n",
      "Threshold = 90.476\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating thresholds and creating binary arrays...\")\n",
    "scores_thresh = []\n",
    "y_bin = np.zeros((len(result),valid[:,1].sum()))\n",
    "nClass = 0\n",
    "for i in range(len(result[0])):\n",
    "    if(not valid[i][1]): continue\n",
    "    print(\"Calculating for\", prevalences.loc[i][\"Diagnostico\"])\n",
    "    temp_result       = result[:,i]\n",
    "    temp_result = np.sort(temp_result, kind = 'mergesort')\n",
    "    ocurrences     = len(result) * prevalences.loc[i][\"Prevalencia\"]\n",
    "    ocurrences     = math.ceil(ocurrences)\n",
    "    scores_thresh.append(temp_result[-ocurrences])\n",
    "    for j in range(len(result)):\n",
    "        if result[j][i] >= scores_thresh[-1]: y_bin[j][nClass] = 1\n",
    "    print(\"Threshold =\",temp_result[-ocurrences])\n",
    "    nClass += 1\n",
    "\n",
    "np.save(\"output/score_bin.npy\", y_bin)\n",
    "np.save(\"output/score_thresholds.npy\", scores_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the greenzone...\n",
      "Done! GreenZone has 537 registers!\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating the greenzone...\")\n",
    "gZoneIdx = []\n",
    "gZoneIds = []\n",
    "gZoneLen = 0\n",
    "for i in range(len(result)):\n",
    "    if y_bin[i].sum() > 0:\n",
    "        gZoneIds.append(db[\"ID_EXAME\"][i])\n",
    "        gZoneIdx.append(i)\n",
    "        gZoneLen += 1\n",
    "print(\"Done! GreenZone has\", gZoneLen, \"registers!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating neural network...\n",
      "Running on a GPU :D\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating neural network...\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Running on a GPU :D\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on a CPU :/\")\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, seq_size):\n",
    "        \n",
    "        print(\"Building NN...\")\n",
    "        embedding_dim = 128\n",
    "        lstm_out_dim = 128\n",
    "        num_embeddings = TOP_WORDS\n",
    "        num_of_classes = 35\n",
    "        \n",
    "        super().__init__()\n",
    "        #Camada de Embedding, o padding_idx é um argumento que eu descobri que é usada para falar para a camada que os números no fim de cada vetor são apenas lixo\n",
    "        self.l1 = nn.Embedding(num_embeddings, embedding_dim, padding_idx = 0)\n",
    "        #Eu não entendo muito bem o que essa camada faz. Pelo que eu entendi é algo probabilístico. Mas ela n altera o shape.\n",
    "#         self.l2 = nn.Dropout(p=0.4)\n",
    "        #A LSTM recebe os Embeddings e cospe o mesmo número de vetores que eu passei para ela. Não sei se eu deveria alterar o número de camadas da LSTM.\n",
    "        #Se usar menos de 2 não dá pra colocar Dropout pq o Dropout é aplicado em todas as camadas menos na última.\n",
    "        self.l3 = nn.LSTM(embedding_dim, lstm_out_dim, dropout = 0.2, num_layers = 2, bidirectional = BIDIRECTIONAL)\n",
    "        #É o seguinte. Como as dimensões de entrada são estáticas, eu adicionei elas manualmente na camada linear para conseguir fazer o flatten.\n",
    "        self.l4 = nn.Flatten()\n",
    "        #Dimensao do vetor de entrada X dimensao da lstm\n",
    "        self.l5 = nn.Linear(seq_size * lstm_out_dim * (2 if BIDIRECTIONAL else 1), num_of_classes)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        #Aqui eu só to passando o input pelas camadas mesmo\n",
    "        x    = self.l1(x)\n",
    "#         x    = self.l2(x)\n",
    "        #A camada de LSTM retorna uma tupla, o vetor que eu quero é a primeira posição da tupla, por isso recebo assim.\n",
    "        #Acho que a segunda camada da LSTM só é util ao passar de uma camada da LSTM para a outra.\n",
    "        x, _ = self.l3(x)\n",
    "        x    = self.l4(x)\n",
    "        x    = self.l5(x)\n",
    "        #Aqui eu aplico o softmax. Especifico o número de dimensões para ser um e tal. Não sei o que não está funcionando :c.\n",
    "        x    = F.softmax(x, dim = 1)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vocabulary...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-347-6af295138ad4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating vocabulary...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTOP_WORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tokenizing texts...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_X\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mfit_on_texts\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m# In how many documents each word occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mwcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Creating vocabulary...\")\n",
    "tokenizer = Tokenizer(num_words = TOP_WORDS, split = ' ')\n",
    "tokenizer.fit_on_texts(texts)\n",
    "print(\"Tokenizing texts...\")\n",
    "train_X   = tokenizer.texts_to_sequences(texts)\n",
    "with open(\"output/tokenizer_\"+str(TOP_WORDS)+\".pickle\", 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(\"X of training data defined!!! Saving...\")\n",
    "np.save(\"output/x_train.npy\", train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping training data...\n",
      "Training input has 203 dimensions!\n"
     ]
    }
   ],
   "source": [
    "print(\"Reshaping training data...\")\n",
    "train_X  = [torch.Tensor(i).type(torch.LongTensor) for i in train_X]\n",
    "train_X  = pad_sequence(train_X, batch_first=True).type(torch.LongTensor)\n",
    "train_y  = torch.Tensor(y_bin)\n",
    "seq_size = len(train_X[0])\n",
    "print(\"Training input has\",seq_size,\"dimensions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building NN...\n",
      "\n",
      "Alexa, play eye of the tiger. It's training time!\n",
      "\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.58it/s]\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.23120196163654327 \n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.60it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.23250506818294525 \n",
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.92it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2117302417755127 \n",
      "\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.01it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.20297332108020782 \n",
      "\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.26it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.195643350481987 \n",
      "\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.19it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.18964971601963043 \n",
      "\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.10it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.18217253684997559 \n",
      "\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.72it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1756848245859146 \n",
      "\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.05it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.17050281167030334 \n",
      "\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.01it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.16472314298152924 \n",
      "\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.92it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 11.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.16041886806488037 \n",
      "\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.59it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.156460702419281 \n",
      "\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.90it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.15246106684207916 \n",
      "\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.92it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.14800426363945007 \n",
      "\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.01it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1449151188135147 \n",
      "\n",
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.99it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.14169198274612427 \n",
      "\n",
      "Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.03it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1389661580324173 \n",
      "\n",
      "Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.05it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.13589085638523102 \n",
      "\n",
      "Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.07it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.13303515315055847 \n",
      "\n",
      "Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.21it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.13040374219417572 \n",
      "\n",
      "Epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.04it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.12802977859973907 \n",
      "\n",
      "Epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.68it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.12615984678268433 \n",
      "\n",
      "Epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.60it/s]\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  9.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.12435920536518097 \n",
      "\n",
      "Epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.43it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.12300518155097961 \n",
      "\n",
      "Epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.05it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.12364915758371353 \n",
      "\n",
      "Epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.97it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.12620235979557037 \n",
      "\n",
      "Epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.05it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.13333012163639069 \n",
      "\n",
      "Epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.02it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.12483090162277222 \n",
      "\n",
      "Epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.24it/s]\n",
      " 67%|██████▋   | 2/3 [00:00<00:00, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.12229582667350769 \n",
      "\n",
      "Epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.12250684946775436 \n",
      "\n",
      "Finished training!\n",
      "Saving model...\n",
      "\n",
      "Completed!\n",
      "You can find all the files that this script has generated in the output folder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net = Net(seq_size).to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0005)\n",
    "loss_function = nn.BCELoss()\n",
    "# Training the model\n",
    "print(\"\\nAlexa, play eye of the tiger. It's training time!\\n\\n\")\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Epoch\", epoch+1)\n",
    "    for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
    "#         print(i, i+BATCH_SIZE)\n",
    "        batch_X = train_X[i:i+BATCH_SIZE]\n",
    "        batch_y = train_y.squeeze()[i:i+BATCH_SIZE]\n",
    "\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        net.zero_grad()\n",
    "        outputs = net(batch_X)\n",
    "        loss    = loss_function(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Loss:\", loss.data.tolist(),\"\\n\")\n",
    "\n",
    "print(\"Finished training!\")\n",
    "print(\"Saving model...\")\n",
    "torch.save(net.state_dict(), \"output/network_model.pth\")\n",
    "print(\"\\nCompleted!\\nYou can find all the files that this script has generated in the output folder.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
